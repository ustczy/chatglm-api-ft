{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08778553",
   "metadata": {},
   "source": [
    "### 安装 git lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7dc84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "!sudo apt-get install git-lfs && git lfs install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b8a58",
   "metadata": {},
   "source": [
    "### 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38b85e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/THUDM/chatglm-6b ../chatglm-6b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd3f6d",
   "metadata": {},
   "source": [
    "### 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065819a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r ./requirement.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742f6cd-6a69-4cb3-995b-667887e3965e",
   "metadata": {},
   "source": [
    "### 数据集准备 \n",
    "\n",
    "准备 `.jsonl` 格式的数据放到 ./data 目录下。数据格式为：\n",
    "\n",
    "\n",
    "{\"q\": \"问题\", \"a\": \"回答\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45107640",
   "metadata": {},
   "source": [
    "### 对数据集进行分词\n",
    "\n",
    "为了避免每次训练的时都要重新对数据集分词，先分好词形成特征后保存成可直接用于训练的数据集。相关参数说明：\n",
    "\n",
    "* model_checkpoint: 模型目录\n",
    "* input_file:  ./data 目录下的数据集文件名\n",
    "* prompt_key:  数据集中 prompt 对应的字段（这里是 q）\n",
    "* target_key:  数据集中 completion 对应的字段（这里是 a)\n",
    "* save_name:  数据集保存目录，分词后的数据保存在 ./data/tokenized_data 下\n",
    "* max_seq_length:  文本最大长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab4698e-5fb8-41fb-917b-a344b11b12d8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-13T07:01:58.340356Z",
     "iopub.status.busy": "2023-07-13T07:01:58.339704Z",
     "iopub.status.idle": "2023-07-13T07:02:02.955376Z",
     "shell.execute_reply": "2023-07-13T07:02:02.954762Z",
     "shell.execute_reply.started": "2023-07-13T07:01:58.340329Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /root/.cache/huggingface/datasets/generator/default-efa56b4c82655941/0.0.0...\n",
      "Generating train split: 0 examples [00:00, ? examples/s]Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\n",
      "Generating train split: 1 examples [00:01,  1.22s/ examples]155 [00:00<?, ?it/s]\u001b[A\n",
      "Generating train split: 229 examples [00:01, 245.78 examples/s]:00, 1292.95it/s]\u001b[A\n",
      "Generating train split: 357 examples [00:01, 375.74 examples/s]:00, 1031.38it/s]\u001b[A\n",
      " 32%|████████████▍                          | 367/1155 [00:00<00:00, 900.90it/s]\u001b[A\n",
      "Generating train split: 491 examples [00:01, 496.28 examples/s]0:00, 905.24it/s]\u001b[A\n",
      "Generating train split: 618 examples [00:01, 637.45 examples/s]:00, 1013.68it/s]\u001b[A\n",
      "Generating train split: 755 examples [00:01, 786.85 examples/s]:00, 1124.49it/s]\u001b[A\n",
      "Generating train split: 885 examples [00:02, 808.30 examples/s]:00, 1104.02it/s]\u001b[A\n",
      "Generating train split: 1000 examples [00:02, 863.93 examples/s]00, 1042.82it/s]\u001b[A\n",
      "100%|█████████████████████████████████████| 1155/1155 [00:01<00:00, 1052.95it/s]\u001b[A\n",
      "Dataset generator downloaded and prepared to /root/.cache/huggingface/datasets/generator/default-efa56b4c82655941/0.0.0. Subsequent calls will reuse this data.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python ./script/tokenize_dataset_rows.py \\\n",
    "    --input_file dataset.jsonl \\\n",
    "    --prompt_key q \\\n",
    "    --target_key a \\\n",
    "    --save_name dataset \\\n",
    "    --max_seq_length 2000 \\\n",
    "    --skip_overlength False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80056f78-037a-4611-a3ac-5fcb6413d18f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 使用 LoRA 微调\n",
    "\n",
    "参数说明：\n",
    "\n",
    "* tokenized_dataset: 分词后的数据集保存目录（即上一步 save_name 的值）\n",
    "* tlora_rank: 设置 LoRA 的秩，推荐为4或8，显存够的话使用8\n",
    "* tper_device_train_batch_size: 每块 GPU 上的 batch size\n",
    "* tgradient_accumulation_steps: 梯度累加，可以在不提升显存占用的情况下增大 batch size\n",
    "* tmax_steps: 训练步数\n",
    "* tsave_steps: 多少步保存一次\n",
    "* tsave_total_limit: 保存多少个checkpoint\n",
    "* tlogging_steps: 多少步打印一次训练情况(loss, lr, etc.)\n",
    "* toutput_dir: 模型文件保存地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a8fb0-e08b-415e-8a14-14b4e1e30940",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-13T07:02:11.440464Z",
     "iopub.status.busy": "2023-07-13T07:02:11.440091Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "'\\nlen(dataset)=1155\\n'\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:08<00:00,  1.01s/it]\n",
      "{'': 0}\n",
      "You are adding a <class 'transformers.integrations.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "/home/pai/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|                                                  | 0/5000 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "{'loss': 1.475, 'learning_rate': 9.914e-05, 'epoch': 0.04}                      \n",
      "{'loss': 0.309, 'learning_rate': 9.814e-05, 'epoch': 0.09}                      \n",
      "{'loss': 0.2181, 'learning_rate': 9.714000000000001e-05, 'epoch': 0.13}         \n",
      "{'loss': 0.251, 'learning_rate': 9.614000000000001e-05, 'epoch': 0.17}          \n",
      "{'loss': 0.2156, 'learning_rate': 9.514e-05, 'epoch': 0.22}                     \n",
      "{'loss': 0.2545, 'learning_rate': 9.414e-05, 'epoch': 0.26}                     \n",
      "{'loss': 0.2086, 'learning_rate': 9.314e-05, 'epoch': 0.3}                      \n",
      "{'loss': 0.1192, 'learning_rate': 9.214000000000001e-05, 'epoch': 0.35}         \n",
      "{'loss': 0.147, 'learning_rate': 9.114e-05, 'epoch': 0.39}                      \n",
      "{'loss': 0.0852, 'learning_rate': 9.014e-05, 'epoch': 0.43}                     \n",
      "{'loss': 0.2847, 'learning_rate': 8.914e-05, 'epoch': 0.48}                     \n",
      "{'loss': 0.1466, 'learning_rate': 8.814e-05, 'epoch': 0.52}                     \n",
      "{'loss': 0.1924, 'learning_rate': 8.714e-05, 'epoch': 0.56}                     \n",
      " 14%|█████▍                                  | 682/5000 [03:08<16:37,  4.33it/s]"
     ]
    }
   ],
   "source": [
    "# 删除上次的微调模型\n",
    "# !rm -rf /mnt/workspace/glm-fine-tuning/weights\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python ./script/chatglm_lora_tuning.py \\\n",
    "    --tokenized_dataset dataset \\\n",
    "    --lora_rank 8 \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --max_steps 5000 \\\n",
    "    --save_steps 200 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --fp16 \\\n",
    "    --remove_unused_columns false \\\n",
    "    --logging_steps 50 \\\n",
    "    --output_dir ./weights/api-fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef793c13-d40a-44eb-ae51-600a45fdf0b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 加载微调模型\n",
    "\n",
    "微调模型保存在上一步配置的 output_dir 目录下。至少需要其中的 adapter_model.bin、adapter_config.json 两个文件才能部署成功"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686d8b3f-ad12-4258-8ff6-7360216ff978",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 启动 web 服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b20ab-1054-4e7e-abe7-c4db08d1b8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ./server/web.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5b141-eec7-4bee-9d99-cf8562bdba6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 通过 API 服务测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22c3e3e4-4b16-4913-a512-b5f093951982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T08:50:59.798885Z",
     "iopub.status.busy": "2023-07-13T08:50:59.798543Z",
     "iopub.status.idle": "2023-07-13T08:51:11.552372Z",
     "shell.execute_reply": "2023-07-13T08:51:11.551799Z",
     "shell.execute_reply.started": "2023-07-13T08:50:59.798861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[?25h/etc/dsw/node/bin/lt -> /etc/dsw/node/lib/node_modules/localtunnel/bin/lt.jsming\u001b[0m \u001b[35maction:finalize\u001b[0m\u001b[0m\u001b[K\n",
      "+ localtunnel@2.0.2\n",
      "added 22 packages from 22 contributors in 10.96s\n"
     ]
    }
   ],
   "source": [
    "# 安装 pyngrok 用来暴露服务\n",
    "\n",
    "!npm install -g localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a1f0e-d66a-484c-ab38-66517f1103df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T08:51:14.453612Z",
     "iopub.status.busy": "2023-07-13T08:51:14.453252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your url is: https://lucky-suns-allow.loca.lt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dtype of attention mask (torch.int64) is not bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-13 17:53:42] \", prompt:\"API：\n",
      "{\n",
      "  \"name\": \"get_okr\",\n",
      "  \"description\": \"查询用户okr\",\n",
      "  \"parameters\": {\n",
      "    \"username\": {\n",
      "      \"type\": \"string\",\n",
      "      \"description\": \"用户名\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "上下文：\n",
      "辰秋的okr\", response:\"'{\\n\"username\": \"辰秋\"\\n}'\"\n",
      "INFO:     140.205.118.27:0 - \"POST / HTTP/1.1\" 200 OK\n",
      "[2023-07-13 17:54:10] \", prompt:\"API：\n",
      "{\n",
      "  \"name\": \"get_okr\",\n",
      "  \"description\": \"查询用户okr\",\n",
      "  \"parameters\": {\n",
      "    \"userList\": {\n",
      "      \"type\": \"List<string>\",\n",
      "      \"description\": \"用户列表\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "上下文：\n",
      "我和默辰的okr\", response:\"'{\\n\"userList\": [\"我和默辰\"]\\n}'\"\n",
      "INFO:     140.205.118.94:0 - \"POST / HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "!lt --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cea84dc-0364-419c-b135-0262ae051a52",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-13T08:49:54.106288Z",
     "iopub.status.busy": "2023-07-13T08:49:54.105941Z",
     "iopub.status.idle": "2023-07-13T08:49:54.112822Z",
     "shell.execute_reply": "2023-07-13T08:49:54.112113Z",
     "shell.execute_reply.started": "2023-07-13T08:49:54.106262Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:35<00:00,  4.42s/it]\n",
      "INFO:     Started server process [16331]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:6006 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# 后台运行 chatlm\n",
    "get_ipython().system_raw(\"python ./server/api.py &\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
