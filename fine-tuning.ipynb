{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08778553",
   "metadata": {},
   "source": [
    "### 安装 git lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7dc84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "!sudo apt-get install git-lfs && git lfs install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b8a58",
   "metadata": {},
   "source": [
    "### 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38b85e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/THUDM/chatglm-6b ../chatglm-6b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd3f6d",
   "metadata": {},
   "source": [
    "### 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065819a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r ./requirement.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742f6cd-6a69-4cb3-995b-667887e3965e",
   "metadata": {},
   "source": [
    "### 数据集准备 \n",
    "\n",
    "准备 `.jsonl` 格式的数据放到 ./data 目录下。数据格式为：\n",
    "\n",
    "\n",
    "{\"q\": \"问题\", \"a\": \"回答\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45107640",
   "metadata": {},
   "source": [
    "### 对数据集进行分词\n",
    "\n",
    "为了避免每次训练的时都要重新对数据集分词，先分好词形成特征后保存成可直接用于训练的数据集。相关参数说明：\n",
    "\n",
    "* model_checkpoint: 模型目录\n",
    "* input_file:  ./data 目录下的数据集文件名\n",
    "* prompt_key:  数据集中 prompt 对应的字段（这里是 q）\n",
    "* target_key:  数据集中 completion 对应的字段（这里是 a)\n",
    "* save_name:  数据集保存目录，分词后的数据保存在 ./data/tokenized_data 下\n",
    "* max_seq_length:  文本最大长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4698e-5fb8-41fb-917b-a344b11b12d8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T08:09:38.466001Z",
     "iopub.status.busy": "2023-07-07T08:09:38.465660Z",
     "iopub.status.idle": "2023-07-07T08:09:42.906323Z",
     "shell.execute_reply": "2023-07-07T08:09:42.905704Z",
     "shell.execute_reply.started": "2023-07-07T08:09:38.465981Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python ./script/tokenize_dataset_rows.py \\\n",
    "    --model_checkpoint ./chatglm-6b \\\n",
    "    --input_file dataset.jsonl \\\n",
    "    --prompt_key q \\\n",
    "    --target_key a \\\n",
    "    --save_name dataset \\\n",
    "    --max_seq_length 2000 \\\n",
    "    --skip_overlength False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80056f78-037a-4611-a3ac-5fcb6413d18f",
   "metadata": {},
   "source": [
    "### 使用 LoRA 微调\n",
    "\n",
    "参数说明：\n",
    "\n",
    "* tokenized_dataset: 分词后的数据集保存目录（即上一步 save_name 的值）\n",
    "* tlora_rank: 设置 LoRA 的秩，推荐为4或8，显存够的话使用8\n",
    "* tper_device_train_batch_size: 每块 GPU 上的 batch size\n",
    "* tgradient_accumulation_steps: 梯度累加，可以在不提升显存占用的情况下增大 batch size\n",
    "* tmax_steps: 训练步数\n",
    "* tsave_steps: 多少步保存一次\n",
    "* tsave_total_limit: 保存多少个checkpoint\n",
    "* tlogging_steps: 多少步打印一次训练情况(loss, lr, etc.)\n",
    "* toutput_dir: 模型文件保存地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a8fb0-e08b-415e-8a14-14b4e1e30940",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T08:09:47.788405Z",
     "iopub.status.busy": "2023-07-07T08:09:47.788055Z",
     "iopub.status.idle": "2023-07-07T08:33:04.422048Z",
     "shell.execute_reply": "2023-07-07T08:33:04.421442Z",
     "shell.execute_reply.started": "2023-07-07T08:09:47.788384Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 删除上次的微调模型\n",
    "# !rm -rf /mnt/workspace/glm-fine-tuning/weights\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python ./script/chatglm_lora_tuning.py \\\n",
    "    --tokenized_dataset dataset \\\n",
    "    --lora_rank 8 \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --max_steps 5000 \\\n",
    "    --save_steps 200 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --fp16 \\\n",
    "    --remove_unused_columns false \\\n",
    "    --logging_steps 50 \\\n",
    "    --output_dir ./weights/api-fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef793c13-d40a-44eb-ae51-600a45fdf0b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 加载微调模型\n",
    "\n",
    "微调模型保存在上一步配置的 output_dir 目录下。至少需要其中的 adapter_model.bin、adapter_config.json 两个文件才能部署成功"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686d8b3f-ad12-4258-8ff6-7360216ff978",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 启动 web 服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b20ab-1054-4e7e-abe7-c4db08d1b8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ./server/web.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5b141-eec7-4bee-9d99-cf8562bdba6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 通过 API 服务测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3e3e4-4b16-4913-a512-b5f093951982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 安装 pyngrok 用来暴露服务\n",
    "\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261a296c-eb92-4881-9c7f-a602f41bddc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T08:08:26.783087Z",
     "iopub.status.busy": "2023-07-07T08:08:26.782745Z",
     "iopub.status.idle": "2023-07-07T08:08:27.928069Z",
     "shell.execute_reply": "2023-07-07T08:08:27.927490Z",
     "shell.execute_reply.started": "2023-07-07T08:08:26.783063Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t=2023-07-07T16:08:26+0800 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy url: https://bfea-47-110-48-61.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "# 启动服务\n",
    "from pyngrok import ngrok, conf\n",
    "\n",
    "pyngrok_config = conf.PyngrokConfig(\n",
    "    auth_token=\"2RjdBXCzDODfrigSoG9RaShlY4w_5mkv6Dp6Bh8yg4YtLXK4E\",\n",
    ")\n",
    "conf.set_default(pyngrok_config)\n",
    "\n",
    "ssh_tunnel = ngrok.connect(8000, \"http\")\n",
    "\n",
    "# 打印代理地址\n",
    "print(\"proxy url:\", ssh_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea84dc-0364-419c-b135-0262ae051a52",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 后台运行 chatlm\n",
    "get_ipython().system_raw(\"python ./server/api.py &\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
